{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf06d5f7",
   "metadata": {},
   "source": [
    "# Flowtron Training\n",
    "\n",
    "This notebook covers:\n",
    "1. Generate spectrogram from a pre-trained model on NGC & or locally available\n",
    "2. Training Flowtron with LJSpeech dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2889508",
   "metadata": {},
   "source": [
    "## 1. Generate spectrogram from a pre-trained model on NGC or local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b8511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed097d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982b2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14d480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d15358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777fb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16f30f04",
   "metadata": {},
   "source": [
    "## 2. Training Flowtron with LJSpeech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba349ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH = 'main'\n",
    "\n",
    "!wget https://raw.githubusercontent.com/aroraakshit/NeMo/$BRANCH/examples/tts/flowtron.py\n",
    "!mkdir conf && cd conf && wget https://raw.githubusercontent.com/aroraakshit/NeMo/$BRANCH/examples/tts/conf/flowtron.yaml && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading LJS dataset\n",
    "# !mkdir data && cd data && wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2 && tar -xvjf archive.tar.bz2 && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ac1960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "[NeMo W 2022-02-04 09:10:12 experimental:27] Module <function get_argmin_mat at 0x7effe37e3670> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-02-04 09:10:12 experimental:27] Module <function getMultiScaleCosAffinityMatrix at 0x7effe37e3700> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-02-04 09:10:12 experimental:27] Module <function parse_scale_configs at 0x7effe37ec160> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-02-04 09:10:12 experimental:27] Module <function get_embs_and_timestamps at 0x7effe37ec1f0> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-02-04 09:10:13 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='ddp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='ddp')` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-02-04 09:10:13 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "[NeMo W 2022-02-04 09:10:13 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:59: LightningDeprecationWarning: Setting `Trainer(flush_logs_every_n_steps=10)` is deprecated in v1.5 and will be removed in v1.7. Please configure flushing in the logger instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo I 2022-02-04 09:10:13 exp_manager:283] Experiments will be logged at /akshita/NeMo/tutorials/tts/nemo_experiments/Flowtron/2022-02-04_09-10-13\n",
      "[NeMo I 2022-02-04 09:10:13 exp_manager:648] TensorboardLogger has been set up\n",
      "[NeMo W 2022-02-04 09:10:13 exp_manager:901] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo W 2022-02-04 09:10:13 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:243: LightningDeprecationWarning: `ModelCheckpoint(every_n_val_epochs)` is deprecated in v1.4 and will be removed in v1.6. Please use `every_n_epochs` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "Number of speakers : 1\n",
      "Number of speakers : 1\n",
      "Number of speakers : 1\n",
      "Number of speakers : 1\n",
      "[NeMo W 2022-02-04 09:10:17 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:287: LightningDeprecationWarning: Base `Callback.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-02-04 09:10:17 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:287: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "Initializing RAdam optimizer\n",
      "\n",
      "  | Name              | Type         | Params\n",
      "---------------------------------------------------\n",
      "0 | speaker_embedding | Embedding    | 128   \n",
      "1 | embedding         | Embedding    | 94.7 K\n",
      "2 | flows             | ModuleList   | 55.4 M\n",
      "3 | encoder           | Encoder      | 5.5 M \n",
      "4 | criterion         | FlowtronLoss | 0     \n",
      "---------------------------------------------------\n",
      "61.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "61.0 M    Total params\n",
      "243.910   Total estimated model params size (MB)\n",
      "Validation sanity check: 0it [00:00, ?it/s][NeMo W 2022-02-04 09:10:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:111: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2022-02-04 09:10:22 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:111: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "Epoch 0:   0%|                                          | 0/150 [00:00<?, ?it/s][NeMo W 2022-02-04 09:10:23 nemo_logging:349] /akshita/NeMo/nemo/collections/tts/modules/flowtron_submodules.py:777: UserWarning: This overload of addcmul_ is deprecated:\n",
      "    \taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "    Consider using one of the following signatures instead:\n",
      "    \taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "      exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "    \n",
      "Epoch 0:  13%|█▎        | 20/150 [00:08<00:56,  2.32it/s, loss=12.5, v_num=0-13]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  15%|█▍        | 22/150 [00:08<00:52,  2.45it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:   4%|█▎                              | 2/50 [00:00<00:11,  4.07it/s]\u001b[A\n",
      "Epoch 0:  16%|█▌        | 24/150 [00:09<00:48,  2.58it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:   8%|██▌                             | 4/50 [00:00<00:09,  5.10it/s]\u001b[A\n",
      "Epoch 0:  17%|█▋        | 26/150 [00:09<00:46,  2.69it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Epoch 0:  19%|█▊        | 28/150 [00:09<00:43,  2.82it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  16%|█████                           | 8/50 [00:01<00:05,  7.55it/s]\u001b[A\n",
      "Epoch 0:  20%|██        | 30/150 [00:10<00:40,  2.95it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  20%|██████▏                        | 10/50 [00:01<00:05,  6.97it/s]\u001b[A\n",
      "Epoch 0:  21%|██▏       | 32/150 [00:10<00:38,  3.06it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Epoch 0:  23%|██▎       | 34/150 [00:10<00:36,  3.20it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  28%|████████▋                      | 14/50 [00:02<00:04,  8.30it/s]\u001b[A\n",
      "Epoch 0:  24%|██▍       | 36/150 [00:10<00:34,  3.28it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  32%|█████████▉                     | 16/50 [00:02<00:04,  7.64it/s]\u001b[A\n",
      "Epoch 0:  25%|██▌       | 38/150 [00:11<00:33,  3.38it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  36%|███████████▏                   | 18/50 [00:02<00:04,  6.80it/s]\u001b[A\n",
      "Epoch 0:  27%|██▋       | 40/150 [00:11<00:31,  3.45it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  40%|████████████▍                  | 20/50 [00:03<00:04,  6.11it/s]\u001b[A\n",
      "Epoch 0:  28%|██▊       | 42/150 [00:11<00:30,  3.52it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  44%|█████████████▋                 | 22/50 [00:03<00:04,  6.42it/s]\u001b[A\n",
      "Epoch 0:  29%|██▉       | 44/150 [00:12<00:29,  3.60it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  48%|██████████████▉                | 24/50 [00:03<00:04,  6.26it/s]\u001b[A\n",
      "Epoch 0:  31%|███       | 46/150 [00:12<00:28,  3.67it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  52%|████████████████               | 26/50 [00:04<00:03,  7.20it/s]\u001b[A\n",
      "Epoch 0:  32%|███▏      | 48/150 [00:12<00:27,  3.76it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  56%|█████████████████▎             | 28/50 [00:04<00:02,  7.51it/s]\u001b[A\n",
      "Epoch 0:  33%|███▎      | 50/150 [00:13<00:26,  3.82it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  60%|██████████████████▌            | 30/50 [00:04<00:02,  7.12it/s]\u001b[A\n",
      "Epoch 0:  35%|███▍      | 52/150 [00:13<00:25,  3.89it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  64%|███████████████████▊           | 32/50 [00:04<00:02,  6.95it/s]\u001b[A\n",
      "Epoch 0:  36%|███▌      | 54/150 [00:13<00:24,  3.96it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  68%|█████████████████████          | 34/50 [00:05<00:02,  7.15it/s]\u001b[A\n",
      "Epoch 0:  37%|███▋      | 56/150 [00:13<00:23,  4.02it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  72%|██████████████████████▎        | 36/50 [00:05<00:01,  7.44it/s]\u001b[A\n",
      "Epoch 0:  39%|███▊      | 58/150 [00:14<00:22,  4.09it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  76%|███████████████████████▌       | 38/50 [00:05<00:01,  6.99it/s]\u001b[A\n",
      "Epoch 0:  40%|████      | 60/150 [00:14<00:21,  4.15it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  80%|████████████████████████▊      | 40/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
      "Epoch 0:  41%|████▏     | 62/150 [00:14<00:20,  4.19it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  84%|██████████████████████████     | 42/50 [00:06<00:01,  6.92it/s]\u001b[A\n",
      "Epoch 0:  43%|████▎     | 64/150 [00:15<00:20,  4.25it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  88%|███████████████████████████▎   | 44/50 [00:06<00:00,  6.47it/s]\u001b[A\n",
      "Epoch 0:  44%|████▍     | 66/150 [00:15<00:19,  4.29it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  92%|████████████████████████████▌  | 46/50 [00:06<00:00,  6.15it/s]\u001b[A\n",
      "Epoch 0:  45%|████▌     | 68/150 [00:15<00:18,  4.32it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Validating:  96%|█████████████████████████████▊ | 48/50 [00:07<00:00,  6.70it/s]\u001b[A\n",
      "Epoch 0:  47%|████▋     | 70/150 [00:15<00:18,  4.38it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "Epoch 0:  47%|████▋     | 71/150 [00:16<00:18,  4.38it/s, loss=12.5, v_num=0-13]\u001b[A\n",
      "                                                                                \u001b[AEpoch 0, global step 19: val_loss reached 1.56547 (best 1.56547), saving model to \"/akshita/NeMo/tutorials/tts/nemo_experiments/Flowtron/2022-02-04_09-10-13/checkpoints/Flowtron--val_loss=1.5655-epoch=0.ckpt\" as top 5\n",
      "Epoch 0:  61%|██████    | 91/150 [01:03<00:41,  1.43it/s, loss=1.52, v_num=0-13]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 93/150 [01:04<00:39,  1.45it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:   4%|█▎                              | 2/50 [00:00<00:17,  2.79it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 95/150 [01:04<00:37,  1.47it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:   8%|██▌                             | 4/50 [00:01<00:10,  4.23it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▍   | 97/150 [01:04<00:35,  1.50it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Epoch 0:  66%|██████▌   | 99/150 [01:05<00:33,  1.52it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  16%|█████                           | 8/50 [00:01<00:05,  7.03it/s]\u001b[A\n",
      "Epoch 0:  67%|██████   | 101/150 [01:05<00:31,  1.55it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  20%|██████▏                        | 10/50 [00:01<00:05,  6.80it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▏  | 103/150 [01:05<00:29,  1.57it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Epoch 0:  70%|██████▎  | 105/150 [01:05<00:28,  1.60it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  28%|████████▋                      | 14/50 [00:02<00:04,  8.11it/s]\u001b[A\n",
      "Epoch 0:  71%|██████▍  | 107/150 [01:06<00:26,  1.62it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  32%|█████████▉                     | 16/50 [00:02<00:04,  7.51it/s]\u001b[A\n",
      "Epoch 0:  73%|██████▌  | 109/150 [01:06<00:24,  1.64it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  36%|███████████▏                   | 18/50 [00:03<00:04,  6.71it/s]\u001b[A\n",
      "Epoch 0:  74%|██████▋  | 111/150 [01:06<00:23,  1.66it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  40%|████████████▍                  | 20/50 [00:03<00:04,  6.06it/s]\u001b[A\n",
      "Epoch 0:  75%|██████▊  | 113/150 [01:07<00:21,  1.68it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  44%|█████████████▋                 | 22/50 [00:03<00:04,  6.39it/s]\u001b[A\n",
      "Epoch 0:  77%|██████▉  | 115/150 [01:07<00:20,  1.71it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  48%|██████████████▉                | 24/50 [00:04<00:04,  6.23it/s]\u001b[A\n",
      "Epoch 0:  78%|███████  | 117/150 [01:07<00:19,  1.73it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  52%|████████████████               | 26/50 [00:04<00:03,  7.15it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▏ | 119/150 [01:07<00:17,  1.75it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  56%|█████████████████▎             | 28/50 [00:04<00:02,  7.43it/s]\u001b[A\n",
      "Epoch 0:  81%|███████▎ | 121/150 [01:08<00:16,  1.77it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  60%|██████████████████▌            | 30/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
      "Epoch 0:  82%|███████▍ | 123/150 [01:08<00:15,  1.80it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  64%|███████████████████▊           | 32/50 [00:05<00:02,  6.89it/s]\u001b[A\n",
      "Epoch 0:  83%|███████▌ | 125/150 [01:08<00:13,  1.82it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  68%|█████████████████████          | 34/50 [00:05<00:02,  7.09it/s]\u001b[A\n",
      "Epoch 0:  85%|███████▌ | 127/150 [01:09<00:12,  1.84it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  72%|██████████████████████▎        | 36/50 [00:05<00:01,  7.39it/s]\u001b[A\n",
      "Epoch 0:  86%|███████▋ | 129/150 [01:09<00:11,  1.86it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  76%|███████████████████████▌       | 38/50 [00:06<00:01,  6.96it/s]\u001b[A\n",
      "Epoch 0:  87%|███████▊ | 131/150 [01:09<00:10,  1.88it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  80%|████████████████████████▊      | 40/50 [00:06<00:01,  7.04it/s]\u001b[A\n",
      "Epoch 0:  89%|███████▉ | 133/150 [01:09<00:08,  1.90it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  84%|██████████████████████████     | 42/50 [00:06<00:01,  6.87it/s]\u001b[A\n",
      "Epoch 0:  90%|████████ | 135/150 [01:10<00:07,  1.92it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  88%|███████████████████████████▎   | 44/50 [00:06<00:00,  6.46it/s]\u001b[A\n",
      "Epoch 0:  91%|████████▏| 137/150 [01:10<00:06,  1.94it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  92%|████████████████████████████▌  | 46/50 [00:07<00:00,  6.14it/s]\u001b[A\n",
      "Epoch 0:  93%|████████▎| 139/150 [01:10<00:05,  1.96it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Validating:  96%|█████████████████████████████▊ | 48/50 [00:07<00:00,  6.68it/s]\u001b[A\n",
      "Epoch 0:  94%|████████▍| 141/150 [01:11<00:04,  1.98it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "Epoch 0:  95%|████████▌| 142/150 [01:11<00:04,  1.99it/s, loss=1.52, v_num=0-13]\u001b[A\n",
      "                                                                                \u001b[AEpoch 0, global step 39: val_loss reached 1.19439 (best 1.19439), saving model to \"/akshita/NeMo/tutorials/tts/nemo_experiments/Flowtron/2022-02-04_09-10-13/checkpoints/Flowtron--val_loss=1.1944-epoch=0.ckpt\" as top 5\n",
      "Epoch 0:  95%|████████▌| 142/150 [01:27<00:04,  1.62it/s, loss=1.52, v_num=0-13]^C\n"
     ]
    }
   ],
   "source": [
    "# sample run to test flowtron\n",
    "\n",
    "!PYTHONPATH=/akshita/NeMo CUDA_VISIBLE_DEVICES=2 HYDRA_FULL_ERROR=1 python flowtron.py train_dataset=\"/akshita/flowtron/filelists/ljs_audiopaths_text_sid_100train_filelist.txt\" validation_dataset=\"/akshita/flowtron/filelists/ljs_audiopaths_text_sid_10val_filelist.txt\" trainer.max_epochs=5 trainer.flush_logs_every_n_steps=10 trainer.val_check_interval=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254fd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full run\n",
    "\n",
    "!PYTHONPATH=/akshita/NeMo CUDA_VISIBLE_DEVICES=2,1 python flowtron.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d21b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel flowtron)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
