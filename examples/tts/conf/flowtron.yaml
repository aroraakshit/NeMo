# This config contains the default values for training Flowtron model on LJSpeech dataset.
# If you want to train model on other dataset, you can change config values according to your dataset.
# Most dataset-specific arguments are in the head of the config file, see below.

name: Flowtron

# paths to datasets
train_dataset: "/akshita/flowtron/filelists/ljs_audiopaths_text_sid_train_filelist.txt"
validation_dataset: "/akshita/flowtron/filelists/ljs_audiopaths_text_sid_val_filelist.txt"

model:
  dummy_speaker_embedding: false
  n_flows: 2
  n_components: 0
  use_gate_layer: true
  n_speaker_dim: 128
  n_text_dim: 512
  optim_algo: "RAdam"
  learning_rate: 1e-3
  weight_decay: 1e-6
  finetune_layers: []
  seed: 1234
  
  speakeremb:
    n_speakers: 1
    n_speaker_dim: ${model.n_speaker_dim}

  textemb:
    n_text: 185
    n_text_dim: ${model.n_text_dim}

  encoder:
    _target_: "nemo.collections.tts.modules.flowtron_submodules.Encoder"
    encoder_n_convolutions: 3
    encoder_embedding_dim: ${model.n_text_dim}
    encoder_kernel_size: 5

  melencoder:
    _target_: "nemo.collections.tts.modules.flowtron_submodules.MelEncoder"
    encoder_n_convolutions: 2
    encoder_embedding_dim: 512
    encoder_kernel_size: 3

  gaussianmixture:
    _target_: "nemo.collections.tts.modules.flowtron_submodules.GaussianMixture"
    n_hidden: ${model.melencoder.encoder_embedding_dim}
    n_components: ${model.n_components}
    n_mel_channels: 80
    fixed_gaussian: true
    mean_scale: 0.0

  arstep:
    n_mel_channels: ${model.gaussianmixture.n_mel_channels}
    n_speaker_dim: ${model.n_speaker_dim}
    n_text_dim: ${model.n_text_dim}
    n_hidden: 1024
    n_attn_channels: 640
    n_lstm_layers: 2
    use_cumm_attention: false

  train_ds:
    dataset:
      _target_: "nemo.collections.tts.data.datalayers.FlowtronData"
      manifest_filepath: ${train_dataset}
      filter_length: 1024
      hop_length: 256
      win_length: 1024
      sampling_rate: 22050
      mel_fmin: 0.0
      mel_fmax: 8000.0
      n_frames_per_step: 1
      max_wav_value: 32768.0
      p_arpabet: 0.5
      cmudict_path: "/akshita/flowtron/data/cmudict_dictionary"
      text_cleaners: ["flowtron_cleaners"]
      speaker_ids: null
      use_attn_prior: true
      attn_prior_threshold: 0.0
      prior_cache_path: "/akshita/attention_prior_cache"
      betab_scaling_factor: 1.0
      keep_ambiguous: false 
      seed: {model.seed}
      randomize: true
    dataloader_params:
      num_workers: 1
      shuffle: true
      sampler: null 
      batch_size: ${model.trainparams.batch_size}
      pin_memory: false
      drop_last: true
  
  validation_ds:
    dataset: ${model.train_ds.dataset}
    dataloader_params:
      num_workers: 1
      shuffle: false
      sampler: null 
      batch_size: ${model.trainparams.batch_size}
      pin_memory: false

  flowtronloss:
    sigma: 1.0
    ctc_loss_weight: 0.01
    use_ctc_loss: true
    blank_logprob: -8
    gate_loss: True

  trainparams:
    ctc_loss_start_iter: 10000
    batch_size: 4
    ignore_layers: []
    include_layers: ["speaker", "encoder", "embedding"]
  
trainer:
  gpus: 1
  max_epochs: 10000000
  num_nodes: 1
  accelerator: ddp
  checkpoint_callback: False  # Provided by exp_manager
  logger: False  # Provided by exp_manager
  gradient_clip_val: 1.0
  flush_logs_every_n_steps: 100
  log_every_n_steps: 50
  val_check_interval: 1000

exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: True
  create_checkpoint_callback: True
  checkpoint_callback_params: 
    save_top_k: 5
    every_n_val_epochs: 1
    always_save_nemo: true